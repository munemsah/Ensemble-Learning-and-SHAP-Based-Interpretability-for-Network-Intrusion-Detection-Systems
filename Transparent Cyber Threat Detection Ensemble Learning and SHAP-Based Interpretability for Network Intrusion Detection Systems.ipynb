{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrpBtJvEhI6r"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix,\n",
        "    accuracy_score, f1_score, precision_score,\n",
        "    recall_score, roc_auc_score, roc_curve, auc,\n",
        "    precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "sns.set_palette(\"deep\")\n"
      ],
      "metadata": {
        "id": "yI6qjC9whtlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/cybersecurityAI/datasets/Cybersecurity_Network_Traffic_Dataset.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "JtODk8XEhNzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
        "print(f\"\\nColumn types:\\n{df.dtypes}\")\n",
        "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
        "print(f\"\\nBasic statistics:\\n{df.describe()}\")\n",
        "print(f\"\\nLabel distribution:\\n{df['label'].value_counts()}\")\n",
        "print(f\"\\nAttack type distribution:\\n{df['attack_type'].value_counts()}\")\n",
        "print(f\"\\nProtocol distribution:\\n{df['protocol'].value_counts()}\")\n",
        "print(f\"\\nIs internal traffic distribution:\\n{df['is_internal_traffic'].value_counts()}\")\n"
      ],
      "metadata": {
        "id": "hYPZqybqhwGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
        "df[\"day_of_week\"] = df[\"timestamp\"].dt.dayofweek\n",
        "df[\"minute\"] = df[\"timestamp\"].dt.minute\n",
        "df[\"is_weekend\"] = (df[\"day_of_week\"] >= 5).astype(int)\n",
        "df[\"is_night\"] = ((df[\"hour\"] >= 22) | (df[\"hour\"] <= 5)).astype(int)\n",
        "\n",
        "df[\"total_bytes\"] = df[\"bytes_sent\"] + df[\"bytes_received\"]\n",
        "df[\"bytes_ratio\"] = df[\"bytes_sent\"] / (df[\"bytes_received\"] + 1)\n",
        "\n",
        "df[\"log_bytes_sent\"] = np.log1p(df[\"bytes_sent\"])\n",
        "df[\"log_bytes_received\"] = np.log1p(df[\"bytes_received\"])\n",
        "df[\"log_total_bytes\"] = np.log1p(df[\"total_bytes\"])\n",
        "\n",
        "df[\"port_diff\"] = abs(df[\"src_port\"] - df[\"dst_port\"])\n",
        "df[\"src_port_is_well_known\"] = (df[\"src_port\"] < 1024).astype(int)\n",
        "df[\"dst_port_is_well_known\"] = (df[\"dst_port\"] < 1024).astype(int)\n",
        "df[\"src_port_is_ephemeral\"] = (df[\"src_port\"] >= 49152).astype(int)\n",
        "df[\"dst_port_is_ephemeral\"] = (df[\"dst_port\"] >= 49152).astype(int)\n",
        "\n",
        "common_ports = [20, 21, 22, 23, 25, 53, 80, 110, 143, 443, 445, 993, 995, 1433, 3306, 3389, 5432, 8080, 8443]\n",
        "df[\"dst_port_common\"] = df[\"dst_port\"].isin(common_ports).astype(int)\n",
        "df[\"src_port_common\"] = df[\"src_port\"].isin(common_ports).astype(int)\n",
        "\n",
        "df[\"has_url\"] = df[\"url\"].notna().astype(int)\n",
        "df[\"url_length\"] = df[\"url\"].fillna(\"\").apply(len)\n",
        "df[\"url_has_login\"] = df[\"url\"].fillna(\"\").str.contains(\"login|logon|auth|signin\", case=False).astype(int)\n",
        "df[\"url_has_admin\"] = df[\"url\"].fillna(\"\").str.contains(\"admin|config|phpmyadmin|setup\", case=False).astype(int)\n",
        "df[\"url_has_id_param\"] = df[\"url\"].fillna(\"\").str.contains(r\"\\?id=\", case=False).astype(int)\n",
        "df[\"url_num_params\"] = df[\"url\"].fillna(\"\").str.count(\"&\") + df[\"url\"].fillna(\"\").str.contains(r\"\\?\").astype(int)\n",
        "df[\"url_depth\"] = df[\"url\"].fillna(\"\").str.count(\"/\")\n",
        "\n",
        "ua_col = df[\"user_agent\"].fillna(\"\")\n",
        "df[\"ua_is_chrome\"] = ua_col.str.contains(\"Chrome\", case=False).astype(int)\n",
        "df[\"ua_is_firefox\"] = ua_col.str.contains(\"Firefox\", case=False).astype(int)\n",
        "df[\"ua_is_windows\"] = ua_col.str.contains(\"Windows\", case=False).astype(int)\n",
        "df[\"ua_length\"] = ua_col.apply(len)\n",
        "\n",
        "df[\"is_internal_traffic\"] = df[\"is_internal_traffic\"].astype(int)\n",
        "\n",
        "le_protocol = LabelEncoder()\n",
        "df[\"protocol_encoded\"] = le_protocol.fit_transform(df[\"protocol\"])\n",
        "\n",
        "src_ip_parts = df[\"src_ip\"].str.split(\".\", expand=True).astype(int)\n",
        "df[\"src_ip_first_octet\"] = src_ip_parts[0]\n",
        "df[\"src_ip_second_octet\"] = src_ip_parts[1]\n",
        "\n",
        "dst_ip_parts = df[\"dst_ip\"].str.split(\".\", expand=True).astype(int)\n",
        "df[\"dst_ip_first_octet\"] = dst_ip_parts[0]\n",
        "df[\"dst_ip_second_octet\"] = dst_ip_parts[1]\n",
        "\n",
        "df[\"src_ip_is_private\"] = (\n",
        "    (src_ip_parts[0] == 10) |\n",
        "    ((src_ip_parts[0] == 172) & (src_ip_parts[1] >= 16) & (src_ip_parts[1] <= 31)) |\n",
        "    ((src_ip_parts[0] == 192) & (src_ip_parts[1] == 168))\n",
        ").astype(int)\n",
        "\n",
        "df[\"dst_ip_is_private\"] = (\n",
        "    (dst_ip_parts[0] == 10) |\n",
        "    ((dst_ip_parts[0] == 172) & (dst_ip_parts[1] >= 16) & (dst_ip_parts[1] <= 31)) |\n",
        "    ((dst_ip_parts[0] == 192) & (dst_ip_parts[1] == 168))\n",
        ").astype(int)\n",
        "\n",
        "print(f\"Features after engineering: {df.shape[1]} columns\")"
      ],
      "metadata": {
        "id": "VQs6x-rwhzuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = [\n",
        "    \"src_port\", \"dst_port\", \"bytes_sent\", \"bytes_received\", \"protocol_encoded\",\n",
        "    \"is_internal_traffic\", \"total_bytes\", \"bytes_ratio\",\n",
        "    \"log_bytes_sent\", \"log_bytes_received\", \"log_total_bytes\",\n",
        "    \"port_diff\", \"src_port_is_well_known\", \"dst_port_is_well_known\",\n",
        "    \"src_port_is_ephemeral\", \"dst_port_is_ephemeral\",\n",
        "    \"dst_port_common\", \"src_port_common\",\n",
        "    \"hour\", \"day_of_week\", \"minute\", \"is_weekend\", \"is_night\",\n",
        "    \"has_url\", \"url_length\", \"url_has_login\", \"url_has_admin\",\n",
        "    \"url_has_id_param\", \"url_num_params\", \"url_depth\",\n",
        "    \"ua_is_chrome\", \"ua_is_firefox\", \"ua_is_windows\", \"ua_length\",\n",
        "    \"src_ip_first_octet\", \"src_ip_second_octet\",\n",
        "    \"dst_ip_first_octet\", \"dst_ip_second_octet\",\n",
        "    \"src_ip_is_private\", \"dst_ip_is_private\"\n",
        "]\n",
        "\n",
        "feature_cols = [c for c in feature_cols if c in df.columns]\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y_binary = df[\"label\"].copy()\n",
        "\n",
        "le_attack = LabelEncoder()\n",
        "y_multi = le_attack.fit_transform(df[\"attack_type\"])\n",
        "attack_classes = le_attack.classes_\n",
        "\n",
        "print(f\"Number of features: {len(feature_cols)}\")"
      ],
      "metadata": {
        "id": "vClAf5qZh1et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=feature_cols)"
      ],
      "metadata": {
        "id": "6uJsnf4Xh157"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
        "    X_scaled, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
        "    X_scaled, y_multi, test_size=0.2, random_state=42, stratify=y_multi\n",
        ")\n",
        "\n",
        "print(f\"Binary - Train: {X_train_b.shape}, Test: {X_test_b.shape}\")\n",
        "print(f\"Multi  - Train: {X_train_m.shape}, Test: {X_test_m.shape}\")"
      ],
      "metadata": {
        "id": "QLKmByRZh3fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_models = {\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=200, max_depth=20, min_samples_split=5,\n",
        "        min_samples_leaf=2, random_state=42, n_jobs=-1, class_weight=\"balanced\"\n",
        "    ),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
        "        n_estimators=200, max_depth=6, learning_rate=0.1,\n",
        "        subsample=0.8, random_state=42\n",
        "    ),\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        max_iter=1000, random_state=42, class_weight=\"balanced\", C=1.0\n",
        "    ),\n",
        "    \"SVM (RBF)\": SVC(\n",
        "        kernel=\"rbf\", C=10, gamma=\"scale\", random_state=42,\n",
        "        probability=True, class_weight=\"balanced\"\n",
        "    ),\n",
        "    \"Neural Network\": MLPClassifier(\n",
        "        hidden_layer_sizes=(128, 64, 32), activation=\"relu\",\n",
        "        max_iter=500, random_state=42, early_stopping=True,\n",
        "        validation_fraction=0.1, batch_size=256, learning_rate=\"adaptive\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "binary_results = {}\n",
        "\n",
        "for name, model in binary_models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    model.fit(X_train_b, y_train_b)\n",
        "\n",
        "    y_pred = model.predict(X_test_b)\n",
        "    y_proba = model.predict_proba(X_test_b)[:, 1]\n",
        "\n",
        "    acc = accuracy_score(y_test_b, y_pred)\n",
        "    f1 = f1_score(y_test_b, y_pred, average=\"weighted\")\n",
        "    prec = precision_score(y_test_b, y_pred, average=\"weighted\")\n",
        "    rec = recall_score(y_test_b, y_pred, average=\"weighted\")\n",
        "    roc = roc_auc_score(y_test_b, y_proba)\n",
        "\n",
        "    binary_results[name] = {\n",
        "        \"accuracy\": acc, \"f1\": f1,\n",
        "        \"precision\": prec, \"recall\": rec,\n",
        "        \"roc_auc\": roc, \"model\": model\n",
        "    }\n",
        "\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"ROC-AUC:   {roc:.4f}\")"
      ],
      "metadata": {
        "id": "RKgN6qxPh3Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Fig. 2 - Confusion Matrix (Gradient Boosting)\n",
        "# =========================================\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "\n",
        "gb_model = binary_results[\"Gradient Boosting\"][\"model\"]\n",
        "y_pred_gb = gb_model.predict(X_test_b)\n",
        "\n",
        "cm = confusion_matrix(y_test_b, y_pred_gb)\n",
        "\n",
        "plt.imshow(cm)\n",
        "plt.title(\"Confusion Matrix - Gradient Boosting\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d1OUpUbI7Sqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Fig. 3 - Precision-Recall Curves\n",
        "# =========================================\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "\n",
        "for name, result in binary_results.items():\n",
        "    model = result[\"model\"]\n",
        "    y_probs = model.predict_proba(X_test_b)[:, 1]\n",
        "    precision, recall, _ = precision_recall_curve(y_test_b, y_probs)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    plt.plot(recall, precision, label=f\"{name} (AUC={pr_auc:.3f})\")\n",
        "\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "atd9eBkl7aJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Fig. 3 - Precision-Recall Curves\n",
        "# =========================================\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "\n",
        "for name, result in binary_results.items():\n",
        "    model = result[\"model\"]\n",
        "    y_probs = model.predict_proba(X_test_b)[:, 1]\n",
        "    precision, recall, _ = precision_recall_curve(y_test_b, y_probs)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    plt.plot(recall, precision, label=f\"{name} (AUC={pr_auc:.3f})\")\n",
        "\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "57947QpQ7cU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "metadata": {
        "id": "IympvC0njHIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# SHAP Explainability - Binary Classification\n",
        "# =========================================\n",
        "\n",
        "# Get best binary model (already computed in your code)\n",
        "best_binary_name = max(binary_results, key=lambda k: binary_results[k][\"f1\"])\n",
        "best_binary_model = binary_results[best_binary_name][\"model\"]\n",
        "\n",
        "print(f\"Using SHAP for model: {best_binary_name}\")\n",
        "\n",
        "# Create SHAP explainer (TreeExplainer for tree-based models)\n",
        "explainer = shap.TreeExplainer(best_binary_model)\n",
        "\n",
        "# Compute SHAP values on test set\n",
        "shap_values = explainer.shap_values(X_test_b)\n",
        "\n",
        "# For binary classification, shap_values[1] corresponds to attack class\n",
        "if isinstance(shap_values, list):\n",
        "    shap_values_to_use = shap_values[1]\n",
        "else:\n",
        "    shap_values_to_use = shap_values\n",
        "\n",
        "# Convert to DataFrame for safety\n",
        "X_test_df = pd.DataFrame(X_test_b, columns=feature_cols)\n",
        "\n",
        "print(\"SHAP values shape:\", np.array(shap_values_to_use).shape)"
      ],
      "metadata": {
        "id": "TpJciWpnjJ3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Fig. 5 - SHAP Global Summary Plot\n",
        "# =========================================\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "\n",
        "shap.summary_plot(\n",
        "    shap_values_to_use,\n",
        "    X_test_df,\n",
        "    feature_names=feature_cols,\n",
        "    show=False\n",
        ")\n",
        "\n",
        "plt.title(\"SHAP Summary Plot - Binary Classification\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FNolO8ZUjLd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar plot of feature importance\n",
        "plt.figure()\n",
        "shap.summary_plot(\n",
        "    shap_values_to_use,\n",
        "    X_test_df,\n",
        "    plot_type=\"bar\",\n",
        "    feature_names=feature_cols,\n",
        "    show=False\n",
        ")\n",
        "plt.title(\"Mean |SHAP| Feature Importance - Binary Classification\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "537pDewwjifT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select one correctly predicted attack sample\n",
        "attack_indices = np.where(y_test_b.values == 1)[0]\n",
        "\n",
        "if len(attack_indices) > 0:\n",
        "    sample_index = attack_indices[0]\n",
        "\n",
        "    print(f\"Explaining sample index: {sample_index}\")\n",
        "\n",
        "    shap.force_plot(\n",
        "        explainer.expected_value,\n",
        "        shap_values_to_use[sample_index],\n",
        "        X_test_df.iloc[sample_index],\n",
        "        matplotlib=True\n",
        "    )"
      ],
      "metadata": {
        "id": "xkcBaQhQjMr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find top important feature\n",
        "shap_importance = np.abs(shap_values_to_use).mean(axis=0)\n",
        "top_feature_index = np.argmax(shap_importance)\n",
        "top_feature_name = feature_cols[top_feature_index]\n",
        "\n",
        "print(\"Top SHAP feature:\", top_feature_name)\n",
        "\n",
        "# =========================================\n",
        "# Fig. 6 - SHAP Dependence Plot\n",
        "# =========================================\n",
        "\n",
        "plt.figure(dpi=300)\n",
        "\n",
        "shap.dependence_plot(\n",
        "    top_feature_name,\n",
        "    shap_values_to_use,\n",
        "    X_test_df,\n",
        "    show=False\n",
        ")\n",
        "\n",
        "plt.title(f\"SHAP Dependence Plot - {top_feature_name}\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "usaHA1l9jOTb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}